{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oncology Clinical Trials Feature Engineering\n",
    "\n",
    "This notebook demonstrates the feature engineering process for the oncology clinical trials dataset, preparing data for predictive modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Add project root to path to import project modules\n",
    "project_root = Path().resolve().parents[0]\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Import feature engineering functions\n",
    "from src.features.build_features import *\n",
    "from src.features.text_features import *\n",
    "\n",
    "# Import visualization functions for feature analysis\n",
    "from src.visualization.visualize import set_plotting_style, plot_correlation_heatmap\n",
    "\n",
    "# Define project directories\n",
    "PROJECT_DIR = project_root\n",
    "PROCESSED_DATA_DIR = PROJECT_DIR / 'data' / 'processed'\n",
    "\n",
    "# Set plotting style\n",
    "set_plotting_style()\n",
    "\n",
    "# Display plots inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Load the processed oncology clinical trials data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most recent processed data file\n",
    "csv_files = list(PROCESSED_DATA_DIR.glob(\"processed_oncology_trials_*.csv\"))\n",
    "\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(\"No processed data files found\")\n",
    "    \n",
    "# Sort by modification time (most recent first)\n",
    "csv_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)\n",
    "latest_data_path = csv_files[0]\n",
    "\n",
    "print(f\"Loading data from {latest_data_path}\")\n",
    "df = pd.read_csv(latest_data_path)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Let's prepare the data for feature engineering by handling missing values and converting data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percent = (missing_values / len(df)) * 100\n",
    "\n",
    "# Create a DataFrame to display missing values\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Values': missing_values,\n",
    "    'Percentage': missing_percent\n",
    "})\n",
    "\n",
    "# Display columns with missing values\n",
    "missing_df[missing_df['Missing Values'] > 0].sort_values('Missing Values', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values based on column type\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Convert enrollment count to numeric\n",
    "df_clean['EnrollmentCount'] = pd.to_numeric(df_clean['EnrollmentCount'], errors='coerce')\n",
    "\n",
    "# Fill missing numeric values with median\n",
    "numeric_cols = df_clean.select_dtypes(include=['int64', 'float64']).columns\n",
    "for col in numeric_cols:\n",
    "    if df_clean[col].isnull().sum() > 0:\n",
    "        median_value = df_clean[col].median()\n",
    "        df_clean[col] = df_clean[col].fillna(median_value)\n",
    "        print(f\"Filled {col} missing values with median: {median_value}\")\n",
    "\n",
    "# Fill missing categorical values with mode\n",
    "categorical_cols = df_clean.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    if df_clean[col].isnull().sum() > 0:\n",
    "        mode_value = df_clean[col].mode()[0]\n",
    "        df_clean[col] = df_clean[col].fillna(mode_value)\n",
    "        print(f\"Filled {col} missing values with mode: {mode_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Features\n",
    "\n",
    "Let's create temporal features from date columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime\n",
    "date_columns = ['StartDate', 'CompletionDate', 'PrimaryCompletionDate']\n",
    "\n",
    "for col in date_columns:\n",
    "    if col in df_clean.columns:\n",
    "        df_clean[col] = pd.to_datetime(df_clean[col], errors='coerce')\n",
    "\n",
    "# Extract year, month, and quarter from start date\n",
    "if 'StartDate' in df_clean.columns:\n",
    "    df_clean['start_year'] = df_clean['StartDate'].dt.year\n",
    "    df_clean['start_month'] = df_clean['StartDate'].dt.month\n",
    "    df_clean['start_quarter'] = df_clean['StartDate'].dt.quarter\n",
    "    \n",
    "# Calculate trial duration if not already present\n",
    "if 'trial_duration_days' not in df_clean.columns and 'CompletionDate' in df_clean.columns:\n",
    "    df_clean['trial_duration_days'] = (df_clean['CompletionDate'] - df_clean['StartDate']).dt.days\n",
    "    \n",
    "    # Handle negative durations (data errors)\n",
    "    df_clean.loc[df_clean['trial_duration_days'] < 0, 'trial_duration_days'] = np.nan\n",
    "    \n",
    "    # Fill missing durations with median\n",
    "    median_duration = df_clean['trial_duration_days'].median()\n",
    "    df_clean['trial_duration_days'] = df_clean['trial_duration_days'].fillna(median_duration)\n",
    "    \n",
    "# Display temporal features\n",
    "temporal_features = [col for col in df_clean.columns if col.startswith('start_') or col == 'trial_duration_days']\n",
    "df_clean[temporal_features].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Features\n",
    "\n",
    "Let's encode categorical features for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical columns\n",
    "categorical_cols = df_clean.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove date columns from categorical columns list\n",
    "categorical_cols = [col for col in categorical_cols if col not in date_columns]\n",
    "\n",
    "print(f\"Categorical columns: {categorical_cols}\")\n",
    "\n",
    "# Create binary indicators for key categorical variables\n",
    "# Sponsor type\n",
    "if 'LeadSponsorClass' in df_clean.columns:\n",
    "    df_clean['is_industry_sponsored'] = (df_clean['LeadSponsorClass'] == 'INDUSTRY').astype(int)\n",
    "    \n",
    "# Phase indicators\n",
    "if 'Phase' in df_clean.columns:\n",
    "    df_clean['is_phase_1'] = df_clean['Phase'].str.contains('Phase 1', na=False).astype(int)\n",
    "    df_clean['is_phase_2'] = df_clean['Phase'].str.contains('Phase 2', na=False).astype(int)\n",
    "    df_clean['is_phase_3'] = df_clean['Phase'].str.contains('Phase 3', na=False).astype(int)\n",
    "    df_clean['is_phase_4'] = df_clean['Phase'].str.contains('Phase 4', na=False).astype(int)\n",
    "    \n",
    "# Study design indicators\n",
    "if 'StudyDesign' in df_clean.columns:\n",
    "    df_clean['is_randomized'] = df_clean['StudyDesign'].str.contains('Randomized', na=False).astype(int)\n",
    "    df_clean['is_double_blind'] = df_clean['StudyDesign'].str.contains('Double Blind', na=False).astype(int)\n",
    "    df_clean['is_single_blind'] = df_clean['StudyDesign'].str.contains('Single Blind', na=False).astype(int)\n",
    "    df_clean['is_open_label'] = df_clean['StudyDesign'].str.contains('Open Label', na=False).astype(int)\n",
    "    \n",
    "# Country indicators\n",
    "if 'LocationCountry' in df_clean.columns:\n",
    "    df_clean['is_multi_country'] = df_clean['LocationCountry'].str.contains(',', na=False).astype(int)\n",
    "    df_clean['has_us_sites'] = df_clean['LocationCountry'].str.contains('United States', na=False).astype(int)\n",
    "    \n",
    "# Display new binary features\n",
    "binary_features = [col for col in df_clean.columns if col.startswith('is_') or col.startswith('has_')]\n",
    "df_clean[binary_features].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Features\n",
    "\n",
    "Let's extract features from text fields like study title and description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if text columns exist\n",
    "text_columns = ['BriefTitle', 'BriefSummary', 'DetailedDescription']\n",
    "available_text_columns = [col for col in text_columns if col in df_clean.columns]\n",
    "\n",
    "if available_text_columns:\n",
    "    # Display sample text data\n",
    "    print(\"Sample text data:\\n\")\n",
    "    for col in available_text_columns[:1]:  # Show just the first text column as example\n",
    "        print(f\"{col} example:\\n{df_clean[col].iloc[0]}\\n\")\n",
    "        \n",
    "    # Create text length features\n",
    "    for col in available_text_columns:\n",
    "        df_clean[f'{col}_length'] = df_clean[col].fillna('').astype(str).apply(len)\n",
    "        \n",
    "    # Display text length statistics\n",
    "    text_length_cols = [col for col in df_clean.columns if col.endswith('_length')]\n",
    "    df_clean[text_length_cols].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Variable Creation\n",
    "\n",
    "Let's create target variables for our predictive models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary completion status target (if not already present)\n",
    "if 'completion_status' not in df_clean.columns and 'OverallStatus' in df_clean.columns:\n",
    "    # Define completed statuses\n",
    "    completed_statuses = ['Completed', 'Terminated', 'Suspended', 'Withdrawn']\n",
    "    \n",
    "    # Create binary target: 1 for completed, 0 for terminated/suspended/withdrawn\n",
    "    df_clean['completion_status'] = (df_clean['OverallStatus'] == 'Completed').astype(int)\n",
    "    \n",
    "    # Filter to only include trials with a definitive outcome\n",
    "    df_modeling = df_clean[df_clean['OverallStatus'].isin(completed_statuses)].copy()\n",
    "    \n",
    "    print(f\"Created binary completion_status target with {df_modeling['completion_status'].sum()} positive examples\"\n",
    "          f\" out of {len(df_modeling)} total examples ({df_modeling['completion_status'].mean():.1%} completion rate)\")\n",
    "else:\n",
    "    df_modeling = df_clean.copy()\n",
    "    \n",
    "# Display target distribution\n",
    "if 'completion_status' in df_modeling.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(x='completion_status', data=df_modeling)\n",
    "    plt.title('Distribution of Trial Completion Status')\n",
    "    plt.xlabel('Completion Status (1 = Completed, 0 = Terminated/Suspended/Withdrawn)')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Let's analyze feature correlations and select the most relevant features for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric features for correlation analysis\n",
    "numeric_features = df_modeling.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Remove target variable from features list if present\n",
    "if 'completion_status' in numeric_features:\n",
    "    numeric_features.remove('completion_status')\n",
    "    \n",
    "if 'trial_duration_days' in numeric_features:\n",
    "    numeric_features.remove('trial_duration_days')  # Remove if we're predicting duration\n",
    "    \n",
    "# Plot correlation with target variables\n",
    "if 'completion_status' in df_modeling.columns:\n",
    "    # Calculate correlation with completion status\n",
    "    completion_corr = df_modeling[numeric_features].corrwith(df_modeling['completion_status']).sort_values(ascending=False)\n",
    "    \n",
    "    # Plot correlations\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    completion_corr.plot(kind='bar')\n",
    "    plt.title('Feature Correlation with Completion Status')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Correlation Coefficient')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "if 'trial_duration_days' in df_modeling.columns:\n",
    "    # Calculate correlation with trial duration\n",
    "    duration_corr = df_modeling[numeric_features].corrwith(df_modeling['trial_duration_days']).sort_values(ascending=False)\n",
    "    \n",
    "    # Plot correlations\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    duration_corr.plot(kind='bar')\n",
    "    plt.title('Feature Correlation with Trial Duration')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Correlation Coefficient')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlation heatmap for key features\n",
    "# Select top features based on correlation with target\n",
    "if 'completion_status' in df_modeling.columns:\n",
    "    # Get top 15 features by absolute correlation\n",
    "    top_features = completion_corr.abs().sort_values(ascending=False).head(15).index.tolist()\n",
    "    \n",
    "    # Add target to the list\n",
    "    top_features.append('completion_status')\n",
    "    \n",
    "    # Plot correlation heatmap\n",
    "    plot_correlation_heatmap(df_modeling, top_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Modeling Dataset\n",
    "\n",
    "Let's prepare the final dataset for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for modeling\n",
    "# For completion status prediction\n",
    "if 'completion_status' in df_modeling.columns:\n",
    "    # Select features with reasonable correlation to target\n",
    "    completion_features = [\n",
    "        'EnrollmentCount', 'start_year', 'is_industry_sponsored',\n",
    "        'is_phase_1', 'is_phase_2', 'is_phase_3', 'is_phase_4',\n",
    "        'is_randomized', 'is_double_blind', 'is_open_label',\n",
    "        'is_multi_country', 'has_us_sites'\n",
    "    ]\n",
    "    \n",
    "    # Add text length features if available\n",
    "    text_length_cols = [col for col in df_modeling.columns if col.endswith('_length')]\n",
    "    completion_features.extend(text_length_cols)\n",
    "    \n",
    "    # Filter to only include available features\n",
    "    completion_features = [col for col in completion_features if col in df_modeling.columns]\n",
    "    \n",
    "    # Create completion prediction dataset\n",
    "    X_completion = df_modeling[completion_features]\n",
    "    y_completion = df_modeling['completion_status']\n",
    "    \n",
    "    print(f\"Prepared completion prediction dataset with {X_completion.shape[1]} features and {len(X_completion)} samples\")\n",
    "    \n",
    "# For duration prediction\n",
    "if 'trial_duration_days' in df_modeling.columns:\n",
    "    # Select features for duration prediction\n",
    "    duration_features = [\n",
    "        'EnrollmentCount', 'start_year', 'is_industry_sponsored',\n",
    "        'is_phase_1', 'is_phase_2', 'is_phase_3', 'is_phase_4',\n",
    "        'is_randomized', 'is_double_blind', 'is_open_label',\n",
    "        'is_multi_country', 'has_us_sites'\n",
    "    ]\n",
    "    \n",
    "    # Add text length features if available\n",
    "    duration_features.extend(text_length_cols)\n",
    "    \n",
    "    # Filter to only include available features\n",
    "    duration_features = [col for col in duration_features if col in df_modeling.columns]\n",
    "    \n",
    "    # Create duration prediction dataset\n",
    "    X_duration = df_modeling[duration_features]\n",
    "    y_duration = df_modeling['trial_duration_days']\n",
    "    \n",
    "    print(f\"Prepared duration prediction dataset with {X_duration.shape[1]} features and {len(X_duration)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Modeling-Ready Dataset\n",
    "\n",
    "Let's save the prepared dataset for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create timestamp for filename\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save modeling dataset\n",
    "modeling_file_path = PROCESSED_DATA_DIR / f\"oncology_trials_modeling_ready_{timestamp}.csv\"\n",
    "df_modeling.to_csv(modeling_file_path, index=False)\n",
    "\n",
    "print(f\"Saved modeling-ready dataset to {modeling_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've performed feature engineering on the oncology clinical trials dataset to prepare it for predictive modeling. Key steps included:\n",
    "\n",
    "1. Data cleaning and missing value handling\n",
    "2. Creation of temporal features from date fields\n",
    "3. Encoding of categorical variables\n",
    "4. Extraction of text features\n",
    "5. Target variable creation for completion status prediction\n",
    "6. Feature selection based on correlation analysis\n",
    "7. Preparation of modeling-ready datasets\n",
    "\n",
    "The prepared dataset is now ready for model training in the next notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}